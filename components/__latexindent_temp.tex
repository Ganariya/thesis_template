
% 提案手法
% 自分の手法・アルゴリズムを再現できるように書く

\chapter{ASrankによる可視化クローリング手法}

この章では，提案手法に関する説明を行う．

序章で述べたとおり，企業やユーザが利用しているFocusedクローリングの問題点として，「あらかじめサイトをリストアップする前作業の多さ」「幅優先探索による関連ページの収集精度の悪さ」「実行途中の結果を見ることのできない不可視化性」が存在する．
そのため本研究ではこれらの問題を解決する提案手法として，アントコロニー最適化手法を用いた可視化クローリング手法を提案する．

この手法は「キーワード」と「キーワード群」のみを定義することで関連ページをクローリングするため，前作業であるリストアップを省くことが可能である．
また，キーワードに関係するWebページに向かうリンクに多くのフェロモンを分泌することによって，クローリングを行う仮想のアリが関連ページに強く惹きつけられるため，収集精度の向上を行える．
グラフデータベースであるNeo4jにWebページの情報を格納するため，クローリング実行中にWebページの構造を確認することが可能である．

この章では，目的をまず説明し，その後にシステム構成と用語の定義，続いて式の定義とアルゴリズム・計算量について説明を行う．

\section{提案手法の目的}

本研究の提案手法の目的は，企業やユーザが現在利用しているFocusedクローリングの問題点を解決することである．

問題点とその解決のための提案は以下である．

\begin{itemize}
    \item あらかじめクローリングするサイトをリストアップする前作業の多さ
        \begin{itemize}
            \item 「キーワード」と「キーワード群」を定義するのみで，クローリングを行う
        \end{itemize}
    \item 幅優先探索による関連ページの収集精度の悪さ 
        \begin{itemize}
            \item アントコロニー最適化手法を応用することによって，関連ページを優先的に掘り出しながらクローリングを行う
        \end{itemize}
    \item 実行途中の結果がを見ることのできない不可視化性
        \begin{itemize}
            \item グラフデータベースであるNeo4jで，クローリング中でもWeb構造を可視化する 
        \end{itemize}
\end{itemize}

これらの解決手段を実現することによって，より企業とユーザは特定のキーワード・ジャンルに関連するページを大量に効率よく
収集することができるのではと考える．

\section{システム構成}

ここでは，提案手法のシステム構成について説明する．

提案手法は主に4つのコンポーネントで構成されている．
各コンポーネントがどのような動作を行っているかを説明する．

\subsubsection{1. アントコロニー最適化}

提案手法のアントコロニー最適化は，巡回セールスマン問題のアントコロニー最適化手法を応用したものである．

仮想のアリがNeo4j上のネットワーク上をフェロモンを頼りに，次に取得すべきWebページを決定する．
そして，クローリング機構にページをクローリングしてもらいNeo4jに登録して，再びアリがNeo4j上のネットワークを移動していく．

また，各サイクルのアリの移動が終わった後は移動した経路のパスのスコアに応じてフェロモンを分泌する．
これによって，次のサイクル以降ではより関連したページを中心に探索が行えると考える．

\subsubsection{2. Neo4j}

Neo4jはグラフデータベースの一つであり，アントコロニー最適化で収集したWebページを，Web構造を維持したまま格納する．

Neo4jには，標準でグラフネットワークとして情報を可視化する機能がついておりクローリング中に実行途中結果を可視化できる．
また，各Webページのタイトルやキーワード，リンクのフェロモン量やヒューリスティックの値など多くの値をノードとエッジに格納できる．

仮想のアリにWebページの構造を渡し，クローリング機構によってクローリングされたWebページを格納する．

\subsubsection{3. クローリング機構}

クローリング機構は，PythonのライブラリであるRequests, BeautifulSoup, MeCabなどで構成されたクローリング用の自作コンポーネントである．

クローリング機構は，仮想のアリが選んだWebページを代わりにクローリング・スクレイピングし，取得したWebページをBeautifulSoupで正規化し解析する．
この正規化では，タイトルの取得や本文中のURLなどの削除，記号の削除など，Webページの情報を綺麗にする．
その後，Mecabという形態素解析エンジンをもとに本文を形態素解析して分かち書きを行う．これによって，ページ評価機構でのページ評価が行いやすくなる．

クローリング機構には，Webページの構造を理解することや，仮想のアリでグラフ上を優先的に探索すること，ページの評価は行わないことに注意したい．


\subsubsection{4. ページ評価機構}
ページ評価機構は，クローリング機構がクローリングして解析した結果をもとに各Webページの評価付やリンクの評価付を行う．

アントコロニー最適化手法では，どのくらいリンクが良いかを表すフェロモンとヒューリスティックという値を各リンクに設定・更新する必要がある．
そのため，ページ評価機構では，各Webページの分かち書きや本文をもとに「キーワードまたはキーワード群をどれくらい含んでいるか？」
「各文書間の類似度はどれくらいか」で，キーワードと文書や，文書と文書間での関連度を計算する．
そして，その関連度をもとに初期フェロモン量とヒューリスティックを決定する．
これによって，仮想のアリが関連度が高いであろうWebページに移動できるようになる．

\section{提案手法におけるアントコロニー最適化}

\subsection{アントコロニー最適化の目的}
提案手法においてアントコロニー最適化を応用する目的は，キーワードに関連するWebページをより高精度に収集するためである．

アントコロニー最適化では，アリの群れの動きをシュミレーションする．このとき，アリはフェロモンという情報を頼りに次の移動すべきパスを選択する．
このフェロモンによって，アリの群れはより良いパスや結果を探索することができる．

そこで，提案手法では，アントコロニー最適化手法をクローリングに応用しキーワードに関連するWebページを優先的に探索する．これによって，
幅優先探索よりも高精度かつ効率的にWebページを収集することができると考える．

また，アントコロニー最適化でアリがフェロモンを頼りに移動する様子は，ユーザがリンクを頼りにより良いコンテンツを探していく様子と類似しており，ユーザの行動を模倣できていると考えられる．
そのため，移動するパス自体に意味があると考えられ，またアリのランダム選択はユーザの気まぐれな移動を模倣していると考えられる．


\subsection{用語の定義}

提案手法で扱う，アントコロニー最適化に関する用語を定義する．

\(ACO_{crawl}\)は，クローリングに応用された提案手法のアントコロニー最適化手法を指す．

{\bf キーワード}は，収集したいWebページのキーワードを指す．例えば，競技プログラミングに関連するWebページを収集したい場合は，キーワードを競技プログラミングとする．

{\bf キーワード群}は，{\bf キーワード}に関連するであろうWebページを収集した際のページ評価付機構で利用するものである．例えば，キーワードに競技プログラミングを指定したとする．
このとき，競技プログラミングに関連しているWebページには他にも「AtCoder」「高橋直大」「Codeforces」といった用語が含まれていると考えられる．
そこで，キーワードに関連したキーワード群を予め定義することにより，Webページがキーワードに似ているかを判定する．

{\bf 精度}は，計\(X\)ページを収集したときキーワードまたはキーワード群を含むWebページ数\(Y\)の割合である\(\frac{Y}{X}\)を指す．
精度が大きいほどよりキーワードに関連しているページを多く収集できるとみなす．

\subsection{式の定義}

ここでは，\(ACO_{crawl}\)におけるアントコロニー最適化手法の式を定義する．
もともとのアントコロニー最適化手法のAnt Systemと同様に3つの式を定義する．

\subsubsection{アリの移動式}

式(\ref{ant_move})をもとにした，アリの移動式である．
アリがどのように次の移動する頂点を決めるかを確率によって決める計算式である．

\(ACO_{crawl}\)においては以下のように定義される．

\begin{equation}
    \label{crawl_move}
    p_{i, j}^k(t) = {\frac{[{\tau}_{i, j}(t)]^{\alpha} + [{\eta}_{i, j}]^{\beta}}{{\sum}_{to{\in}D_i} \ [{\tau}_{i, to}(t)]^{\alpha}+[{\eta}_{i, to}]^{\beta}}}
\end{equation}

異なる点として，フェロモン\([{\tau}_{i, j}(t)]^{\alpha}\)とヒューリスティック\([{\eta}_{i, j}]^{\beta}\)の積ではなく和を求める点がある．
ヒューリスティックとして，リンクをつなぐページ間の類似度，またはリンク先のページのキーワードとの関連度を利用するため，場合によってはヒューリスティックが0となることが存在する．
この場合，積のままではいくらフェロモンが大きくなってもヒューリスティックが0のため永遠に選択されない．
そこで，和の演算とすることで，ヒューリスティック値を採用しながらフェロモンを用いた探索を行っている．

本研究では，\(\alpha=1, \beta=1\)としている．

\subsubsection{フェロモン分泌式}

式(\ref{add_pheromone})をもとにした，アリのフェロモンの分泌量を計算する式である．

\(ACO_{crawl}\)においては以下のように定義される．

\begin{equation}
    \label{crawl_add_pheromone}
    {\Delta}{\tau}_{i, j}^k = {\frac{\sum_{t=1}^{len(path^k)} score(path^k[t])}{len(path^k)}}
\end{equation}

\(path_k\)はアリ\(k\)がこのサイクル中に移動したノードの移動パスの配列である．\(path^k[3]\)は，アリ\(k\)が3番目に訪問したWebページのノードを表す．

\(score(page)\)は，Webページをスコア評価機構によって評価付したときのスコアである．
このスコアが大きいほどよりキーワードに類似しており，アリがより惹きつけられる．
具体的な関数\(score\)の実装は，実験や設定によって異なる．

これらのスコアの和を求めて，アリの移動したパスの長さで割ることで，移動したパスの1ページあたりのスコアを求める．
ただし，フェロモンやヒューリスティックの比率，蒸発率などの関係から，フェロモンの分泌量に係数をかけなければいけない場合が存在する．

\subsubsection{フェロモン蒸発式}

式(\ref{pheoromone_update})をもとにしたフェロモンの蒸発に関する式である．
式(\ref{crawl_add_pheromone})によって求めた分泌フェロモン量をもとに，アリ\(k\)が移動したパスにフェロモンを実際に分泌させる．

\(ACO_{crawl}\)においては以下のように定義される．

\begin{equation}
    \label{crawl_pheoromone_update}
    {\tau}_{i, j}(t+ 1) = {(1-\rho)}{\times}{\tau}_{i, j}(t) + {\sum}_{i=1}^N {\Delta}_{i, j}^k
\end{equation}

元の式と同様に\(\rho\)は蒸発係数であり，\(\rho\)が大きいほどこれまでのフェロモンが蒸発し，サイクル\(t\)におけるフェロモンの分泌の
影響度が大きくなる．


\section{提案手法におけるNeo4j}

\subsection{Neo4jの目的}

提案手法においてNeo4jを利用する目的は，直感的にデータを格納するかつクローリング中に実行結果を確認するためである．

従来のリレーショナルデータベースに各Webページ間のリンクを格納するとスキーマの定義より，ページとリンク，そしてページのグループなど多くのテーブルが必要となる．
収集したデータ数が増加するほど，リレーショナルデータベースの結合の操作がボトルネックとなってしまう．
また，Web構造が分離されてしまい本来のネットワークグラフを構築することが難しい．そのため，
グラフネットワーク状にWebページとそのリンクをノードとリレーションとして直感的に格納できるNeo4jを利用する．

また，従来のクローリング手法ではExcelやCSVといった表形式のデータを実行後に格納するのが基本であると考えた．これでは仮にクローリングに途中で失敗していた場合
時間が無駄になってしまう．そのため，実行中でも
Web構造をグラフネットワークとして可視化できるNeo4jを利用する．

\subsection{用語の定義}

提案手法における，Neo4jの用語の定義について説明する．

{\bf ノード}は，Neo4jに格納されたWebページを指す．各ノードは，Webページのタイトルやアンカー，分かち書きされた本文，スコアなどを属性として持つ．

{\bf リレーション}は，Neo4jに格納されたWebページの出リンクを指す．Webページは出リンクを多く含んでおり，Webページ\(X\)からWebページ\(Y\)へ向かう
出リンクをリレーションと定義する．


\subsection{Neo4jのスキーマ定義}

提案手法における，Neo4jのスキーマの定義について説明する．

インターネットのWeb構造は頂点と有向辺からなるグラフ\(G=(V, E)\)と定義でき，
\(V\)は収集したWebページのノード集合，\(E\)は収集したWebページ間のリンク集合と表す．

ノードのスキーマは表\ref{tab:node_scheme}のように表される．

\begin{table}[ht]
    \caption{ノードのスキーマ}
    \label{tab:node_scheme}
    \begin{center}
        \begin{tabular}{ccc} \bhline{1pt}
            属性名             & データ型         & 詳細                    \\ \hline
            url             & string        & ページURL                 \\ 
            domain          & string        & ページのドメイン               \\
            title           & string        & ページのタイトル               \\
            anchors         & array(string) & ページに含まれる出リンクの配列        \\
            body            & string        & ページの本文(URL，数字，特殊記号を除く) \\
            wakati          & string        & 分かち書きされたページの本文         \\
            score           & double        & ページの評価値                \\
            visit\_times    & int           & ページのアクセス回数             \\
            characteristics & array(string) & ページの特徴的な単語の配列          \\
            is\_expanded    & bool          & すでにこのノードが展開されたか        \\
            created         & unix(double)  & ノードの作成時刻    \\ \hline     
        \end{tabular}
    \end{center}
\end{table}

本来は，上記のノードのスキーマにNeo4jによって自動で追加されるidの属性が存在する．

また，リレーションのスキーマは表\ref{tab:edge_scheme}のように表される．

\begin{table}[hbtp]
    \caption{エッジのスキーマ}
    \label{tab:edge_scheme}
    \begin{center}
        \begin{tabular}{ccc} \bhline{1pt}
            属性名         & データ化型  & 詳細                        \\ \hline
            edge\_id    & string & ID(from\_url + to\_url)   \\
            pheromone   & double & エッジのフェロモン量                \\
            similarity  & double & from\_urlとto\_urlのページの類似度 \\
            heuristic   & double & エッジのヒューリスティック値            \\
            from\_url   & string & エッジの出リンク元                 \\
            to\_url     & string & エッジの出リンク先                 \\
            pass\_times & int    & エッジを通過した回数       \\ \hline
        \end{tabular}
    \end{center}
\end{table}

\pagebreak

ノードならびにエッジの例は図\ref{fig:node_edge_property}である．


\begin{figure}[hbtp]
    \begin{center}
        \includegraphics[width=0.8\linewidth]{images/chapter4/node_edge.png}
    \end{center}
    \caption{ノードとエッジのプロパティ}
    \label{fig:node_edge_property}
\end{figure}

\pagebreak


\section{フローチャート}

ここでは，\(Ant_{crawl}\)のフローチャートについて説明する．

フローチャートに出てくる変数は表である．

\begin{table}[hbtp]
    \caption{フローチャートの変数}
    \label{tab:flowchart_variable}
    \begin{center}
        \begin{tabular}{ccc} \bhline{1pt}
            変数名        & データ化型  & 詳細                        \\ \hline
            \(key\)    & string & ID(from\_url + to\_url)   \\
            \(keywords\)   & double & エッジのフェロモン量                \\
            \(MAX_{cycle}\)  & double & from\_urlとto\_urlのページの類似度 \\
            \(k\)   & double & エッジのヒューリスティック値            \\
            \(cycle\)   & string & エッジの出リンク元                 \\
            \(v^k\)     & string & エッジの出リンク先                 \\
            \(path^k\) & int    & エッジを通過した回数       \\ \hline
        \end{tabular}
    \end{center}
\end{table}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.5\linewidth]{images/chapter4/aco_crawl_top.png}
    \end{center}
    \caption{フローチャート　AntCrawl}
    \label{fig:flowchart_ant_crawl_top}
\end{figure}

\pagebreak

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.7\linewidth]{images/chapter4/aco_crawl_second.png}
    \end{center}
    \caption{フローチャート　AntCrawl cycle}
    \label{fig:flowchart_ant_crawl_second}
\end{figure}

\pagebreak

図\ref{fig:flowchart_ant_crawl_top}，図\ref{fig:flowchart_ant_crawl_second}の通り，アントコロニー最適化を用いたクローリングでは\(MAX_{cycle}\)回だけ

\begin{enumerate}
    \item \(N\)体のアリの\(cycle\)回の確率移動
    \item 各アリごとの移動パスの分泌フェロモン計算
    \item 分泌フェロモンを元にグラフのフェロモンを更新
\end{enumerate}

を行う．

また，図\ref{fig:flowchart_ant_crawl_second}の通り，ノード\(v^k\)のis\_expanded属性がFalseの場合のみ
ノード\(v^k\)を実際にクローリングし本文解析やスコア評価を行うとしている．
これによって，一度クローリングしたものは二度目以降は行わず，実行時間の短縮と効率化を図っている．
ただし，情報の鮮度などは落ちるため企業やユーザが実際に利用する場合は，更新日時などを考慮して再クローリングを行い
情報の鮮度を保つべきである．

\section{計算量概算}

ここでは，計算量の概算について説明する．


